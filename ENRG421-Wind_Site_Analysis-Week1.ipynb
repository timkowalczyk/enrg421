{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wind Site Analysis, Week 1: Wind Speed Distributions from Anemometer Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### ENRG 421, Spring 2022"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I. <font color=green>***Introduction***<font color=black>\n",
    "\n",
    "An important first step in the development of a wind energy project is building a clear understanding of the wind resource available at the site of interest. It is common practice to collect wind velocity data (speed and direction) at the site of interest using a modern anemometer tower with sensors and a digital interface for recording wind velocity data electronically. The images below (excerpted from [[1]](#refs)) show an example of what these installations look like:<br>\n",
    "![image.png](https://raw.githubusercontent.com/timkowalczyk/enrg421/master/NREL-snip.png)\n",
    "    In this lab we will use wind resource data to determine the wind speed distributions for a site, to estimate the available power, and to analyze the impact of a yaw system that aligns the turbine axis with the incident wind.<br><br>\n",
    "    \n",
    "As with previous notebooks, every time you see a <font color=purple>***Try it out for yourself:***<font color=black> prompt, you should edit or provide new code in the cell below the prompt. Likewise, every time you see a <font color=purple>***Questions for reflection:***<font color=black> prompt, please provide your answer(s) to the question(s) that follow the prompt in the Markdown cells immediately following each question.<br>\n",
    "\n",
    "Because this lab builds on skills developed in the previous labs, you may find it useful to refer back to code snippets from earlier labs, or even to borrow and modify code snippets directly from those previous labs!<br><br>\n",
    "\n",
    "Here are the goals for Weeks 1 and 2 on Wind Site Analysis:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "II. <font color=green>***Goals***<font color=black>\n",
    "* To gain experience wrangling raw open-source data for importing into Python\n",
    "* To produce accurate Weibull-type wind speed distributions from anemometer data\n",
    "* To estimate the power that could be generated from a turbine sited in the survey area\n",
    "* To perform a cost/benefit analysis of an active yaw system that turns the turbine into the wind"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "III. <font color=green>***Land Acknowledgment***<font color=black>\n",
    "\n",
    "The data we'll work with in this lab, published on the open-access energy information data repository [OpenEI](https://openei.org/datasets/), were obtained on the lands of indigenous peoples of North America through the Native American anemometer loan program.<sup>[[2]](#refs)</sup> You may choose either tribe's data set to work with for this lab.<br><br>\n",
    "    \n",
    "Below you'll find a video or two to provide some context for the peoples and land behind each data set. Once you've selected a data set, please watch the paired video(s) to learn a little bit about the tribe and its stewardship of the lands on which the data we're analyzing were obtained.\n",
    "    \n",
    "*Note:* It appears the raw data was removed or is otherwise unavailable from the OpenEI as of the time of our lab (!) Instead of providing a direct link below, the original Excel workbooks are available on Canvas.\n",
    "\n",
    "* Anishinaabe, Ojibwe of the Keweenaw Bay Indian Community (MI):\n",
    "    * Data set is posted on Canvas\n",
    "    * [Video](https://www.youtube.com/watch?v=FnNS26btMXA)\n",
    "* Shoshone of the Wind River Nation (WY):\n",
    "    * Data set is posted on Canvas\n",
    "    * [Video](https://www.youtube.com/watch?v=c_FN3tLiRUg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IV. <font color=green>***Importing wind speed data***<font color=black>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The wind speed data is provided in a spreadsheet, which you can export to csv format in Excel for import using the `csv` module that you used in the Thermal Image Analysis lab. However, the data you worked with in the previous lab was already \"cleaned\" in the sense that empty cells, column headers, etc had already been removed from the csv file before you imported it. Here you'll be working with the Excel spreadsheet directly from the source, so you will probably need to make some modifications to successfully import the data you want.<br>\n",
    "\n",
    "For this lab, I recommend editing the Excel spreadsheet directly to get it into a form that you can directly import into Python in csv format. You have flexibility here; if you want, you can break the spreadsheet up into multiple independent csv files and import them one by one, or import everything at once and then organize the data into appropriate arrays in Python. Here is a skeleton template to get you started."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=purple>***Try it out for yourself:***<font color=black> In the cell below, produce a data array (i.e. a matrix), from the data in your Excel spreadsheet, that stores the data from the \"Frequency\" tab in the spreadsheet.\n",
    "\n",
    "You have flexibility in how you choose to store the data. For example, each row could include the minimum and maximum wind speeds $v_{\\mathrm{min}}$ and $v_{\\mathrm{max}}$ defining that row's range of wind speeds; or you could store just $v_{\\mathrm{min}}$ and infer the associated $v_{\\mathrm{max}}$ from the $v_{\\mathrm{min}}$ of the next row.<br><br>\n",
    "    \n",
    "Here is a skeleton template (from the Thermal Imaging lab) for importing csv data to get you started.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from csv import reader\n",
    "from numpy import array, zeros\n",
    "\n",
    "D = [[]] # Empty array to store data\n",
    "\n",
    "datafilename = example.csv # replace with actual filename here\n",
    "with open(datafilename) as csv_file:\n",
    "    csv_reader = reader(csv_file)\n",
    "    linecounter = 0\n",
    "    for row in csv_reader:\n",
    "        data = [float(x) for x in row] # Convert data from strings to numbers\n",
    "        D.append(data)\n",
    "\n",
    "D = array(D[1:]) #Trims unnecessary header info, converts to numpy array\n",
    "csv_file.close()\n",
    "print(D)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=purple>***Questions for reflection:***<font color=black>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. What modifications did you make to the spreadsheet in order to import the raw data? (This needn't be a precise accounting, just a brief summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. The `csv` module contains a variety of functions for extracting data from csv files. Under what kinds of circumstances do you think it might be easier to use the functions in the `csv` module directly instead of editing the spreadsheet?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "V. <font color=green>***Producing wind speed histograms***<font color=black>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=purple>***Try it out for yourself:***<font color=black> In the cell below, modify the code to generate a single histogram showing the total wind speed distribution summed over all directions (\"Sum\" column in the spreadsheet).<br>\n",
    "*Hint:* You can extract a row or column from a numpy array as follows:\n",
    "* Extracting (\"slicing\") the first row from array `D`: `row1 = D[0]` (Python counts rows/columns from zero, not one!)\n",
    "* Extracting (\"slicing\") the first column from array `D`: `col1 = D[:,0]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from numpy import array\n",
    "\n",
    "x = array([0.0, 1.0, 2.0])  # Replace this with imported array of wind speeds here\n",
    "y = array([5.0, 9.0, 7.0])  # Replace this with imported array of wind speed frequencies here\n",
    "fig, axes = plt.subplots(tight_layout=True)\n",
    "axes.bar(x,y)\n",
    "plt.xlabel('$v$ (m/s)')\n",
    "plt.ylabel('$F(v)$')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=purple>***Try it out for yourself:***<font color=black> In the cell below, paste your code from above and modify it further to produce a single plot that stacks the 16 histograms for the different wind directions together. You can stack bars on top of one another by repeating the `axes.bar()` function, using different $y$ values for the different directions.<br>\n",
    "    \n",
    "*Hint:* You are welcome to copy and paste `axes.bar()` 15 times to accomplish this; that said, if you want to try to condense the code a bit, you can take advantage of Python's `for` loop feature that repeats an action a specified number of times. The syntax looks like this: suppose we've placed the wind speed data for each direction in arrays `y[i]` where `i` indexes the different directions (for example, `i=0` for N(orth), `i=1` for NNE, etc.) Then:\n",
    "\n",
    "```for i in range(16):\n",
    "        axes.bar(x,y[i])```\n",
    "\n",
    "would create the same results as\n",
    "    \n",
    "```axes.bar(x,y[0])\n",
    "   axes.bar(x,y[1])\n",
    "   ... #(repeated 13 times)\n",
    "   axes.bar(x,y[15])```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=purple>***Questions for reflection:***<font color=black>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Compare the sum of the stacked directional histograms (second plot) to your omnidirectional histogram (first plot). Do they have the same shape? Should they have the same shape? Briefly discuss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. In which direction is the most common wind speed the *largest*? In other words, which of these distributions has the largest mode?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VI. <font color=green>***Fitting a Weibull distribution to wind speed histograms***<font color=black>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The anemometer data is representative of the continuous distribution of wind speeds observed at the site. With this data in hand, we can now infer the shape of the continuous distribution. As we discussed in ENRG 320, the mathematical distribution that best matches observed wind speed patterns with the smallest number of free parameters is the Weibull distribution,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$F(v) = \\left(\\frac{k}{c}\\right)\\left(\\frac{v}{c}\\right)^{k-1}\\exp\\left[-\\left(\\frac{v}{c}\\right)^k\\right]$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To introduce the Weibull distribution into our code, we can define a Python function. New functions in Python must be **defined** before they can be **called**. To define a function, for example, $f(x) = 3e^x+2x$, we write:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import exp\n",
    "\n",
    "def f(x,k):\n",
    "    return 3*exp(x)+2*x*k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's a different but equivalent approach that introduces an intermediate quantity $y$ to store the output of the function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import exp\n",
    "\n",
    "def f(x):\n",
    "    y = 3*exp(x)+2*x\n",
    "    return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=purple>***Try it out for yourself:***<font color=black> In the cell below, define a function `F_Weibull()` that returns the value of the Weibull distribution for given values of the wind speed $v$ and Weibull parameters $k$ and $c$.\n",
    "    \n",
    "*Hint:* You can pass multiple inputs to a function by listing them inside the parentheses separated by commas, for example, `def f(x,y,z):`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's try and use this new function to fit the wind speed histogram we generated in part V."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=purple>***Try it out for yourself:***<font color=black> In the cell below:\n",
    "1. Paste your code that produces the total wind speed histogram across all directions.\n",
    "2. Then modify the code so that it also plots the Weibull distribution for $k=2, c=1$.\n",
    "3. Finally, play with the values of $k$ and $c$ to see if you can find values for these parameters that match the data reasonably well.\n",
    "    \n",
    "*Hint 1:* To plot the Weibull distribution, it may be useful to use the `linspace()` function from `numpy` which we used in Week 1 to define the list of wind speeds at which to compute and plot F(v). One approach is to put this distribution on the same axis as the histogram, you can use `axes.plot()` with the list of wind speeds generated by `linspace()`\n",
    "    \n",
    "*Hint 2:* The histogram is normalized to the total number of wind speed measurements, while the Weibull distribution is normalized to 1. To see them both on the same scale, you'll need to scale the entire Weibull distribution by a prefactor equal to the total number of wind speed measurements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=purple>***Questions for reflection:***<font color=black>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. How well does your best set of parameters align with the data? Is the fit more sensitive to one of the parameters than to the other? If so, which one?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. How might we try to automate the process of fitting the parameters of the Weibull distribution to the data? See if you can find a way to do this in Python (e.g. by searching the web for ideas about how to fit data to a mathematical distribution in Python). You don't need to actually do it this week; here we're just looking for a short description of what tools or existing modules you might use to automate this fitting. We will continue this thread next week!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Congratulations** on completing the Week 3 notebook! Please remember to save all of your answers and edits before uploading your .ipynb file to the Week 3 assignment on Canvas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='refs'></a>\n",
    "### References Cited"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Koracin *et al.* \"[Tall Tower Wind Energy Monitoring and Numerical Model Validation in Northern Nevada](https://www.nrel.gov/docs/fy16osti/62894.pdf)\". National Renewable Energy Laboratory, SubcontractReport NREL/SR-5000-62894, October 2015.\n",
    "2. T. Jimenez. \"[The Wind Powering America Anemometer Loan Program: A Retrospective](https://pdfs.semanticscholar.org/6d2c/1a0a0fff48a58ee27fc40d4c9ce5fd0d5db4.pdf)\". National Renewable Energy Laboratory, Technical Report NREL/TP-7A30-57351, May 2013."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
